{
 "metadata": {
  "name": "",
  "signature": "sha256:6e11586cc1dc91420e696cc4d9f692d6d8b2e41c1346e90b64f48ba8e0fca2c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "First, do this to get the ipython notebook\n",
      "\n",
      "git checkout student\n",
      "git commit -am ...\n",
      "git checkout master\n",
      "git pull origin master\n",
      "git checkout student\n",
      "git merge master\n",
      "\n",
      "#  if you have a \"merge conflict\"\n",
      "git checkout --ours Labs/DS*\n",
      "git add Labs/DS*\n",
      "git commit -m \"merge from master fix\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lab : Neural Nets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import python_nn_function as nn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Functions\n",
      "\n",
      "sigmoid<br/>\n",
      "sigmoidGradient<br/>\n",
      "<br/>\n",
      "initialize_theta<br/>\n",
      "print_theta<br/>\n",
      "<br/>\n",
      "nn_cost<br/>\n",
      "nn_predict<br/>\n",
      "back_prop<br/>\n",
      "fit<br/>\n",
      "<br/>\n",
      "translate_to_binary_array<br/>\n",
      "train_test_split<br/>\n",
      "<br/>\n",
      "nn_test<br/>\n",
      "iris_test<br/>\n",
      "digits_test<br/>\n",
      "XOR_test<br/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "data_set = load_iris()\n",
      "\n",
      "data = data_set.data\n",
      "data[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = nn.translate_to_binary_array(data_set.target)\n",
      "  \n",
      "target[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split into train, test sets\n",
      "data_train, data_test, target_train, target_test = nn.train_test_split(data, target, .75)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hidden_unit_length_list = [2]\n",
      "print \"input_unit_count: %s\" % data_train.shape[1]\n",
      "print \"output_class_count: %s\" % target_train.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Theta_L = nn.initialize_theta(data_train.shape[1], \n",
      "                              target_train.shape[1], \n",
      "                              hidden_unit_length_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "nn.fit?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Definition:  nn.fit(X_train, Y_train, Theta_L=[], lmda=1e-05, epochs=2, learning_rate=1.0, momentum_rate=0.1, learning_acceleration=1.05, learning_backup=0.5, X_test=None, Y_test=None)\n",
      "\n",
      "Docstring:\n",
      "fit() calls the predict and back_prop functions for the \n",
      "given number of cycles, tracks error and error improvement rates\n",
      "  \n",
      "Parameters:\n",
      "  X_train - np.array of training data with dimension n_observations by n_features\n",
      "  Y_train - np.array of training classes with dimension n_observations by n_classes\n",
      "  Theta_L - list of theta terms as np.arrays where each theta has dimensions n_units[l+1] by n_units[l]+1\n",
      "  lmda - regularization term\n",
      "  epochs -  integer of number of times to update Theta_L\n",
      "  X_test - np.array of training data with dimension n_observations by n_features\n",
      "  Y_test - np.array of training classes with dimension n_observations by n_classes\n",
      "\n",
      "Returns\n",
      "  Theta_L - list of theta terms from layer l to l+1\n",
      "  J_list - list of result of cost function for each epoch\n",
      "  Learning_rates - list of learning rates used for each epoch\n",
      "\n",
      "Notes\n",
      "  Training and Test data are assumed to be in random order; mini-batch processing does not need to re-randomize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs=2500                   # --> the number of iterations that will be utilized to calculate Theta\n",
      "learning_rate=0.5\n",
      "momentum_rate=0.1             # --> allows a change to the weights to persist for a number of adjustment cycles.                                                                                                                                                                                                                    \n",
      "learning_acceleration=1.05\n",
      "learning_backup=0.5\n",
      "\n",
      "Theta_L, J_list, learning_rates, J_test_list = nn.fit(data_train, \n",
      "                                                      target_train, \n",
      "                                                      Theta_L, \n",
      "                                                      1e-5, \n",
      "                                                      epochs, \n",
      "                                                      learning_rate, \n",
      "                                                      momentum_rate, \n",
      "                                                      learning_acceleration, \n",
      "                                                      learning_backup, \n",
      "                                                      #data_test, \n",
      "                                                      #target_test\n",
      "                                                      )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_N, Y_pred = nn.nn_predict(data_test, Theta_L)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Given X:'\n",
      "print data_test[:5]\n",
      "print 'Actual Y, Predicted Y:'\n",
      "for p in zip(target_test[:10], np.round(Y_pred[:10],3)):\n",
      "    print p\n",
      "print\n",
      "print 'Results of the Cost Function on Test Set'\n",
      "print nn.nn_cost(target_test , Y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Theta_L"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test-Y_pred.round()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(target_test-Y_pred.round())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_pred.round()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}